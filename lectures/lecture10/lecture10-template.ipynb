{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plan for today\n",
    "\n",
    "1.  **Aggregation and reduction**\n",
    "\n",
    "    -   Performing computations on (subset of) data\n",
    "\n",
    "2.  **Combining data**\n",
    "\n",
    "    -   Concatenation\n",
    "    -   Merging / joining\n",
    "    -   Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to use files in the local data/ directory\n",
    "DATA_PATH = '../../data'\n",
    "\n",
    "# Uncomment this to load data directly from GitHub\n",
    "# DATA_PATH = 'https://raw.githubusercontent.com/richardfoltyn/FIE463-V25/main/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Display only 6 rows of data\n",
    "pd.set_option('display.max_rows', 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Grouping and aggregation with pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Aggregation and reduction\n",
    "\n",
    "*Split-apply-combine* operations:\n",
    "\n",
    "1. *Split* data into groups based on some criteria;\n",
    "2. *Apply* some function to each group separately; and\n",
    "3. *Combine* the results into a single `DataFrame` or `Series`.\n",
    "\n",
    "See [cheat sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) for an illustration of such operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Aggregations of whole Series or DataFrames\n",
    "\n",
    "Pandas supports the usual set of aggregation functions, e.g.:\n",
    "\n",
    "-   [`mean()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html)\n",
    "-   [`sum()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html)\n",
    "-   [`std()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.std.html), \n",
    "    [`var()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.var.html)\n",
    "-   [`quantile()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html)\n",
    "-   [`count()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.count.html)\n",
    "-   [`min()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.min.html), \n",
    "    [`max()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.max.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: compute mean of all numerical columns*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to Titanic passenger data CSV file\n",
    "file = f'{DATA_PATH}/titanic.csv'\n",
    "\n",
    "# Read in Titanic passenger data, set PassenderId column as index\n",
    "df = pd.read_csv(file, index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: NaNs are automatically ignored (unlike with NumPy)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***\n",
    "### Aggregations of subsets of data (grouping)\n",
    "\n",
    "-   Apply aggregation by group\n",
    "    -   Groups are defined based on values of columns or the index\n",
    "    -   Usually a categorical variable or an identifier for a household/individual/firm/period/...\n",
    "    \n",
    "-   Can group by *multiple* columns or index levels at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: apply groupby-operations to SCF data*\n",
    "\n",
    "-   We use a 10% sample of the\n",
    "    [Survey of Consumer Finances](https://www.federalreserve.gov/econres/scfindex.htm) \n",
    "    (SCF) for the years 1989-2022\n",
    "-   Use [`groupby()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)\n",
    "    to group by employment state (column `empl`):\n",
    "\n",
    "    1. working for someone else\n",
    "    2. self-employed\n",
    "    3. retired/disabled\n",
    "    4. not in labor force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to SCF data file\n",
    "file = f'{DATA_PATH}/SCF/SCF_10pct.csv'\n",
    "\n",
    "# Read in SCF data, set id column as index\n",
    "df = pd.read_csv(file, index_col='id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Built-in aggregations\n",
    "\n",
    "- [`mean()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.mean.html):\n",
    "    averages within each group\n",
    "- [`sum()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sum.html):\n",
    "    sum values within each group\n",
    "- [`std()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.std.html), \n",
    "    [`var()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.var.html): \n",
    "    within-group standard deviation and variance\n",
    "-   [`median()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.median.html):\n",
    "    compute median within each group\n",
    "- [`quantile()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.quantile.html):\n",
    "    compute quantiles within each group\n",
    "- [`size()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.size.html): \n",
    "    number of observations in each group\n",
    "- [`count()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.count.html):\n",
    "    number of non-missing observations in each group\n",
    "- [`first()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.first.html), \n",
    "    [`last()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.last.html): \n",
    "    first and last elements in each group\n",
    "-   [`min()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.min.html), \n",
    "    [`max()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.max.html): \n",
    "    minimum and maximum elements within a group\n",
    "\n",
    "See the [official documentation](https://pandas.pydata.org/docs/user_guide/groupby.html#built-in-aggregation-methods) for a complete list."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Example: Number of elements within each group*\n",
    "\n",
    "-   Note: `size()` and `count()` are two different functions!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: Return first observation of each group*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "Use the SCF data set to perform the following aggregations:\n",
    "<ol>\n",
    "    <li>Compute the average net worth (<TT>networth</TT>) by marital status (<TT>married</TT>).</li>\n",
    "    <li>Compute the median value of the primary residence (<TT>houses</TT>) by education (<TT>educ</TT>).</li>\n",
    "    <li>Compute the home ownership rate (<TT>owner</TT>) by marital status (<TT>married</TT>) <i>and</i> the sex of the household head (<TT>female</TT>).</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***\n",
    "#### Writing custom aggregations\n",
    "\n",
    "-   Sometimes we want to use aggregations *not* implemented in pandas\n",
    "-   Use [`agg()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html)\n",
    "    to perform custom aggregations\n",
    "-   Important: `agg()` operates on a single column at a time (cannot combine data from multiple columns)\n",
    "\n",
    "    -   Use [`apply()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.apply.html) to perform aggregations based on multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: compute mean via `agg()`*\n",
    "\n",
    "-   Compute mean age by employment status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: custom aggregation*\n",
    "\n",
    "-   Count number of households with a household head older than 60 years by employment state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Applying multiple functions at once\n",
    "\n",
    "-  Applying multiple functions to a **single** column\n",
    "\n",
    "    -   Functions are passed in as a *list*\n",
    "\n",
    "-  Applying multiple functions to **multiple** columns\n",
    "\n",
    "    -   Use so-called *named aggregation*\n",
    "    -   Columns and functions are passed in as a *dictionary*:\n",
    "\n",
    "    ```python\n",
    "    groups.agg(\n",
    "        new_column_name1=('column_name1', 'operation1'),\n",
    "        new_column_name2=('column_name2', 'operation2'),\n",
    "        ...\n",
    "    )\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*Example: Applying multiple functions to a **single** column*\n",
    "\n",
    "-   Compute mean *and* median age by employment status"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: Applying multiple functions to **multiple** columns*\n",
    "\n",
    "-   Compute the following by employment status in a single call to `agg()`:\n",
    "    1.  Median age\n",
    "    2.  Smallest net worth\n",
    "    3.  Share of female household heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "Use the SCF data set to perform the following aggregations:\n",
    "<ol>\n",
    "    <li>Compute the minimum, maximum and average age (<TT>age</TT>) by marital status <i>and</i> sex (<TT>married</TT> and <TT>female</TT>) in a single <TT>agg()</TT> operation.</li>\n",
    "    <li>Compute the number of observations, the home ownership rate (<TT>owner</TT>), and median net worth (<TT>networth</TT>) by education level (<TT>educ</TT>) in a single <TT>agg()</TT> operation.\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Transformations\n",
    "\n",
    "-   Same principle as aggregations, but size of the result object remains unchanged\n",
    "-   Useful for computations that involve individual and aggregate data\n",
    "-   Performed with [`transform()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.transform.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: assign group-specific mean*\n",
    "\n",
    "- Compute home ownership rate by eduction, store as `frac_owners` column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: Deviation from median net worth*\n",
    "\n",
    "-   For each household, compute difference to median net worth of households with the same education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "Use the SCF data set to answer the following questions:\n",
    "<ol>\n",
    "    <li>Compute how much a household pays more in rent (<TT>rent</TT>) than the average household with the same \n",
    "    marital (<TT>married</TT>) and employment status (<TT>empl</TT>). Restrict your analysis\n",
    "    to households who do not own their residence (<TT>owner = 0</TT>).</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Resampling and aggregation\n",
    "\n",
    "-   Use [`resample()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.resample.html) to aggregate time series data to lower frequency\n",
    "-   Argument to `resample()` determines frequency and index of resulting data, e.g.:\n",
    "\n",
    "    -   `'YE'` aggregation to years, index is end of year\n",
    "    -   `'QE'` aggregation to quarters, index is end of quarter\n",
    "    -   `'ME'` aggregation to months, index is end of month\n",
    "    -   `'W'` aggregations to weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: Resampling the NASDAQ index*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to NASDAQ data file\n",
    "file = f'{DATA_PATH}/stockmarket/NASDAQ.csv'\n",
    "\n",
    "# Read in NASDAQ data, set Date column as index\n",
    "df = pd.read_csv(file, index_col='Date', parse_dates=True)\n",
    "\n",
    "# Keep observations after 2024\n",
    "df = df.loc['2024':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "<p>\n",
    "Use the daily NASDAQ data for 2024 and compute the percentage change from the first to the last trading day within each month.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Concatenating and merging data\n",
    "\n",
    "Combine several `Series` or `DataFrame` objects:\n",
    "\n",
    "1. [`pd.concat()`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html): combine multiple Series/DataFrames by appending observations (rows) or columns.\n",
    "2. [`pd.merge()`](https://pandas.pydata.org/docs/reference/api/pandas.merge.html): match observations from one Series/DataFrame with observations from another Series/DataFrame and combine these into a _merged_ DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create demo series\n",
    "import pandas as pd \n",
    "\n",
    "a = pd.Series(['A1', 'A2', 'A3'])\n",
    "b = pd.Series([f'B{i}' for i in range(5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: Concatenating two Series along the row axis*\n",
    "\n",
    "-   Might need to reset index of result object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: Concatenating along the column axis*\n",
    "\n",
    "-   Need to specify `axis=1` argument\n",
    "-   Use `keys` to specify column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "<ol>\n",
    "    <li>Create a new <TT>Series</TT> with observations <TT>['C1', 'C2']</TT>.</li>\n",
    "    <li>Using the previously created <TT>Series</TT> <TT>a</TT> and <TT>b</TT>, concatenate all three objects along the row axis and create a new (unique) index.</li>\n",
    "    <li>Repeat the previous step, but now concatenate along the column axis. Assign the column names <TT>'Column1'</TT>, <TT>'Column2'</TT>, and <TT>'Column3'</TT>.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create demo DataFrames\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create 2 x 2 DataFrame of string data\n",
    "df_a = pd.DataFrame(np.array(('A1', 'A2', 'A3', 'A4')).reshape((2, 2)))\n",
    "\n",
    "# Create 2 x 3 DataFrame of string data\n",
    "df_b = pd.DataFrame(np.array([f'B{i}' for i in range(6)]).reshape((2, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating along the column axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: Concatenating two DataFrames along the column axis*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Might need to reset non-unique column index\n",
    "-   Use `keys` argument to `concat()` to add outer level to column index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating along the row axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: Concatenating rows with identical columns*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: Concatenating rows with different columns*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "Use the data files located in the folder <TT>../../data/FRED</TT> to perform the following tasks:\n",
    "<ol>\n",
    "    <li>Load the data in <TT>FRED_monthly_1950.csv</TT> and <TT>FRED_monthly_1960.csv</TT> into two different DataFrames.\n",
    "        The files contain monthly macroeconomic time series for the 1950s and 1960s, respectively.\n",
    "        <p>\n",
    "        <i>Hint:</i> Use <TT>pd.read_csv(..., parse_dates=['DATE'])</TT> to automatically parse strings stored in the <TT>DATE</TT> column as dates.\n",
    "        </p>\n",
    "        </li>\n",
    "    <li>Concatenate these DataFrames along the row dimension to get a total of 240 observations.</li>\n",
    "    <li>Set the column <TT>DATE</TT> as index for the newly created DataFrame.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in FRED data for 1950s and 1960s\n",
    "df_1950 = pd.read_csv(f'{DATA_PATH}/FRED/FRED_monthly_1950.csv', parse_dates=['DATE'])\n",
    "df_1960 = pd.read_csv(f'{DATA_PATH}/FRED/FRED_monthly_1960.csv', parse_dates=['DATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Merging and joining data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of merges\n",
    "\n",
    "We can merge DataFrames `A` and `B` in various ways:\n",
    "\n",
    "1.  *one-to-one*: Unique keys in `A` and `B`\n",
    "2.  *many-to-one*: Unique keys in `A`, non-unique keys in `B`\n",
    "3.  *many-to-many*: Non-unique keys in both `A` and `B` (avoid this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation in pandas\n",
    "\n",
    "1.  [`pd.merge()`](https://pandas.pydata.org/docs/reference/api/pandas.merge.html): function that takes as argument the *two* DataFrames to be merged,\n",
    "    e.g.,\n",
    "    \n",
    "    ```python\n",
    "    result = pd.merge(df_A, df_B)\n",
    "    ```\n",
    "2.  [`df.merge()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html): method of a specific `DataFrame` object, takes the other `DataFrame` as argument, e.g.,\n",
    "    \n",
    "    ```python\n",
    "    result = df_A.merge(df_B)\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controlling the resulting data set\n",
    "\n",
    "Merge methods:\n",
    "\n",
    "1.  `how='inner'` (_inner join_): _intersection_ of keys that are present in _both_ data sets\n",
    "2.  `how='outer'` (_outer join_): _union_ of keys present in either of the data sets\n",
    "3.  `how='left'` (_left join_): all identifiers from the _left_ data set are in the result\n",
    "4.  `how='right'` (_right join_): all identifiers from the _right_ data set are in the result\n",
    "\n",
    "Illustration: Each circle represents the keys present in the left (`df1`) or right (`df2`) DataFrames. The merge method controls which subset of keys is retained in the merge result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Join types](join-methods.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Merging with `merge()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create first DataFrame with 2 rows\n",
    "df_a = pd.DataFrame({'key': [0, 1], 'value_a': ['A0', 'A1']})\n",
    "\n",
    "# Create second DataFrame with 2 rows\n",
    "df_b = pd.DataFrame({'key': [1, 2], 'value_b': ['B1', 'B2']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `pd.merge()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: one-to-one merges*\n",
    "\n",
    "-   Argument `on` controls on which columns to match (default: use all overlapping columns)\n",
    "-   Argument `how` controls which rows to keep in result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `DataFrame.merge()`\n",
    "\n",
    "-   Equivalent to `pd.merge()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: Merging with overlapping column names*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to common name 'value'\n",
    "df_a = df_a.rename(columns={'value_a': 'value'})\n",
    "df_b = df_b.rename(columns={'value_b': 'value'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "Use the data files located in the folder <TT>../../data/FRED</TT> to perform the following tasks:\n",
    "<ol>\n",
    "    <li>Load the data in <TT>CPI.csv</TT> and <TT>GDP.csv</TT> into two different DataFrames.\n",
    "        The files contain monthly data for the Consumer Price Index (CPI) and quarterly data for GDP, respectively.\n",
    "        <p>\n",
    "        <i>Hint:</i> Use <TT>pd.read_csv(..., parse_dates=['DATE'])</TT> to automatically parse strings stored in the <TT>DATE</TT> column as dates.\n",
    "        </p>\n",
    "        </li>\n",
    "    <li>Merge the CPI with the GDP time series with \n",
    "    <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html\"><TT>merge()</TT></a> \n",
    "    using a left join (<TT>how='left'</TT>). How many observations does the resulting DataFrame have?</li>\n",
    "    <li>Merge the CPI with the GDP time series with <TT>merge()</TT> using an inner join (<TT>how='inner'</TT>). How many observations does the resulting DataFrame have,\n",
    "        and why is this different from the previous case?</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in CPI and GDP data\n",
    "df_cpi = pd.read_csv(f'{DATA_PATH}/FRED/CPI.csv', parse_dates=['DATE'])\n",
    "df_gdp = pd.read_csv(f'{DATA_PATH}/FRED/GDP.csv', parse_dates=['DATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Joining with `join()`\n",
    "\n",
    "The `DataFrame` method \n",
    "[`join()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html) \n",
    "is a convenience wrapper around \n",
    "[`pd.merge()`](https://pandas.pydata.org/docs/reference/api/pandas.merge.html):\n",
    "\n",
    "1.  `join()` can be called _only_ directly on the `DataFrame` object\n",
    "2.  `join()` always operates on the _index_ of the other `DataFrame`\n",
    "3.  `join()` by default performs a `left` join, whereas `merge()` performs an `inner` join\n",
    "\n",
    "Use `join()` if you want to join DataFrames which have a similar index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: joining DataFrames*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create first DataFrame with 2 rows\n",
    "df_a = pd.DataFrame(['A0', 'A1'], columns=['value_a'], index=[0, 1])\n",
    "\n",
    "# Create second DataFrame with 2 rows\n",
    "df_b = pd.DataFrame(['B1', 'B2'], columns=['value_b'], index=[1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "Use the data files located in the folder <TT>../../data/FRED</TT> to perform the following tasks:\n",
    "<ol>\n",
    "    <li>Load the data in <TT>CPI.csv</TT> and <TT>GDP.csv</TT> into two different DataFrames.\n",
    "        The files contain monthly data for the Consumer Price Index (CPI) and quarterly data for GDP, respectively.\n",
    "        <br/>\n",
    "        <i>Hint:</i> Use <TT>pd.read_csv(..., parse_dates=['DATE'])</TT> to automatically parse strings stored in the <TT>DATE</TT> column as dates.\n",
    "        </li>\n",
    "    <li>Set the <TT>DATE</TT> column as the index for each of the two DataFrames.</li>\n",
    "    <li>Merge the CPI with the GDP time series with \n",
    "    <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html\"><TT>join()</TT></a>. \n",
    "    Do this with both a left and an inner join.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Dealing with missing values\n",
    "\n",
    "-   Often created as result of `pd.merge()` or `pd.concat()` if operands don't have the same row or column index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two DataFrames with partially overlapping keys\n",
    "df_a = pd.DataFrame({'key': [0, 1], 'value_a': ['A0', 'A1']})\n",
    "df_b = pd.DataFrame({'key': [1, 2], 'value_b': ['B1', 'B2']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping missing values\n",
    "\n",
    "Missing values can be dropped by either\n",
    "\n",
    "1. Using [`dropna()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)\n",
    "    or selecting a subset of observations with a boolean operation such as \n",
    "    [`notna()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notna.html).\n",
    "2. Avoiding the missing values in the first place, e.g., by using `merge(..., how='inner')`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: Dropping missing values*\n",
    "\n",
    "- Use _outer/left/right join_ and drop missing data with `dropna()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: Avoiding missing values in the first place*\n",
    "\n",
    "- E.g., use _inner join_ when merging data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling missing values\n",
    "\n",
    "Instead of dropping data, we can impute missing values in various ways:\n",
    "\n",
    "1.  [`fillna()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html): replace missing data with user-specified values\n",
    "2.  [`ffill()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ffill.html) and \n",
    "    [`bfill()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bfill.html): fill missing values\n",
    "    forward or backward from adjacent non-missing observations\n",
    "3.  [`interpolate()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html): interpolate missing values based on non-missing ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: Replacing missing values with `fillna()`*\n",
    "\n",
    "- Specify one value for _entire_ `DataFrame`\n",
    "- Specify different value for each column using a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: forward- or backward-filling missing values*\n",
    "\n",
    "- Use [`ffill()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ffill.html) to forward-fill\n",
    "- Use [`bfill()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bfill.html) to backward-fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example: linear interpolation*\n",
    "\n",
    "- Use [`interpolate()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.interpolate.html) to interpolate missing _numerical_ data (e.g., `method='linear'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1.0, 2.0, 3.0, np.nan, 5.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "Use the data files located in the folder <TT>../../data/FRED</TT> to perform the following tasks:\n",
    "<ol>\n",
    "    <li>Load the data in <TT>CPI.csv</TT> and <TT>GDP.csv</TT> into two different DataFrames.\n",
    "        The files contain monthly data for the Consumer Price Index (CPI) and quarterly data for GDP, respectively.\n",
    "        <br/>\n",
    "        <i>Hint:</i> Use <TT>pd.read_csv(..., parse_dates=['DATE'])</TT> to automatically parse strings stored in the <TT>DATE</TT> column as dates.\n",
    "        </li>\n",
    "    <li>Merge the CPI with the GDP time series with <TT>merge()</TT> using a left join. This creates missing values in the <TT>GDP</TT>\n",
    "    column.</li>\n",
    "    <li>Impute the missing GDP values using <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.Series.interpolate.html\"><TT>interpolate()</TT></a> \n",
    "    and replace the missing values in column <TT>GDP</TT>.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FIE463",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
