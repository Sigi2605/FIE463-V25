{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Polynomial under- and overfitting\n",
    "\n",
    "Consider the following non-linear model,\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_i &= f(x_i) + \\epsilon_i \\\\\n",
    "f(x) &= \\cos\\left(\\frac{3}{2} \\pi x \\right) \\\\\n",
    "\\epsilon_i &\\stackrel{\\text{iid}}{\\sim} N(0, \\sigma_{\\epsilon}^2)\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $y_i$ is a trigonometric function of $x_i$ but is measured with an additive error $\\epsilon_i$. In this exercise, we are going to approximate $y_i$ using polynomials in $x_i$ of varying degrees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Part 1: Creating and plotting a sample\n",
    "\n",
    "The function `fcn()` implements the true relationship $y=f(x)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fcn(x):\n",
    "    \"\"\"\n",
    "    True function without errors\n",
    "    \"\"\"\n",
    "    return np.cos(1.5 * np.pi * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this function, create a sample of size $N=50$ where the $x_i$ are randomly drawn from a uniform distribution on the interval $[0, 1]$ and \n",
    "$\\sigma_{\\epsilon} = 0.2$ (initialize your RNG with a seed of 1234).\n",
    "Then generate $y_i$ according to the equation given above. \n",
    "\n",
    "Create a scatter plot of the sample $(x_i, y_i)$ and add a line depicting the true relationship without measurement error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Part 2: Polynomial approximations\n",
    "\n",
    "In order to approximate this relationship using polynomials, you first want to visualize how the polynomial degree affects the model fit. To this end, complete the template for `plot_poly_degree()` below to create a figure with 6 sub-plots,\n",
    "each showing the predicted values for a polynomial of degree $d$, where $d \\in \\{0, 1, 2, 3, 10, 15\\}$.\n",
    "Each panel should additionally show the sample scatter plot and the true function $y = f(x)$.\n",
    "\n",
    "How does the quality of the approximation change as you increase $d$? Do higher-order polynomials always perform better?\n",
    "\n",
    "*Hints:* \n",
    "\n",
    "-   You should build a pipeline, e.g., using \n",
    "[`make_pipeline()`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html),\n",
    "which combines the \n",
    "[`PolynomialFeatures`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)\n",
    "transformation and \n",
    "[`LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "to approximate $y$ as a polynomial in $x$.\n",
    "\n",
    "-   When creating polynomials with `PolynomialFeatures(..., include_bias=True)`, you need to fit the model *without*\n",
    "    an additional intercept as the intercept is already included in the polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_poly_degrees(degrees, X, y):\n",
    "    \"\"\"\n",
    "    Fit and plot polynomial regression models of different degrees.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    degrees : array-like\n",
    "        List of polynomial degrees to fit and plot\n",
    "    X : array-like\n",
    "        Explanatory variable\n",
    "    y : array-like\n",
    "        Response variable\n",
    "    \"\"\"\n",
    "\n",
    "    # Create figure with 3 columns\n",
    "    ncol = 3\n",
    "    nrow = int(np.ceil(len(degrees) / ncol))\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrow, ncol, figsize=(8, 5), sharex=True, sharey=True, constrained_layout=True\n",
    "    )\n",
    "\n",
    "    # x-values for predicting & plotting\n",
    "    xvalues = np.linspace(0.0, 1.0, 101)\n",
    "    # True y-values\n",
    "    y_true = fcn(xvalues)\n",
    "\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "\n",
    "        # Degree for current sub-plot\n",
    "        d = degrees[i]\n",
    "\n",
    "        # TODO: Create polynomial + estimation pipeline\n",
    "\n",
    "        # TODO: Fit the model to the sample data\n",
    "\n",
    "        # TODO: Predict the response variable for the x-values\n",
    "\n",
    "        # TODO: Plot predicted values\n",
    "\n",
    "        # Plot true relationship\n",
    "        ax.plot(xvalues, y_true, color='black', lw=1.0)\n",
    "        # Plot sample as scatter plot\n",
    "        ax.scatter(X, y, s=20, color='none', edgecolor='steelblue', lw=0.75)\n",
    "        ax.set_ylim((-1.5, 1.5))\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Part 3: Optimal polynomial degree with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to find the optimal polynomial degree using cross-validation. To this end,\n",
    "implement the function `compute_average_mse()` using the template below.\n",
    "\n",
    "This function takes as arguments the polynomial degree $d$, the \n",
    "sample observations $(X, y)$ and the number of splits `n_splits`, and returns the mean squared error (MSE) for the\n",
    "training and test samples averaged across all splits. \n",
    "\n",
    "*Hint:* To compute the MSE for each test sample, you can use \n",
    "[`mean_squared_error()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def compute_average_mse(d, X, y, n_splits=10):\n",
    "    \"\"\"\n",
    "    Compute mean squared error averaged across splits in k-fold cross-validation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d : int\n",
    "        Degree of polynomial\n",
    "    x : array-like\n",
    "        Explanatory variable\n",
    "    y : array-like\n",
    "        Response variable\n",
    "    n_splits : int\n",
    "        Number of splits in k-fold cross-validation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mse_train : array-like\n",
    "        Average MSE on training sample over all splits\n",
    "    mse_test : array-like\n",
    "        Average MSE on test sample over all splits\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: create polynomial + estimation pipeline\n",
    "\n",
    "    # Split sample into train/test blocks for k-fold validation\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "\n",
    "    # list to store MSE for each CV split\n",
    "    mse_train_splits = []\n",
    "    mse_test_splits = []\n",
    "\n",
    "    # Manually iterate over folds (train/test combinations)\n",
    "    for itrain, itest in kf.split(X):\n",
    "\n",
    "        # Extract training and test data for current split\n",
    "        X_train = X[itrain]\n",
    "        X_test = X[itest]\n",
    "\n",
    "        y_train = y[itrain]\n",
    "        y_test = y[itest]\n",
    "\n",
    "        # TODO: Fit the model to current training data\n",
    "\n",
    "        # TODO: Predict the response variable on both the training and test data\n",
    "\n",
    "        # TODO: Compute the mean squared error for both the training and test data\n",
    "\n",
    "        # TODO: Append the MSE to mse_train_splits and mse_test_splits\n",
    "\n",
    "    # Compute average MSE over all splits\n",
    "    mse_train = np.mean(mse_train_splits)\n",
    "    mse_test = np.mean(mse_test_splits)\n",
    "\n",
    "    return mse_train, mse_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Part 4: Computing the MSE for each hyperparameter\n",
    "\n",
    "Using the function you wrote, compute the average MSEs for a sequence of 16 polynomial degrees $d = 0, 1, 2, \\dots, 15$ using 10 splits.\n",
    "Use the MSE statistics to plot the validation curve showing the average MSE on the $y$-axis against $d$ on the $x$-axis.\n",
    "Which degree $d$ results in the lowest average MSE on the test sample? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Part 5: Plotting the fitted model\n",
    "\n",
    "Re-estimate the model using the optimal polynomial degree you just found and create a scatter plot with the original data, the true function $y = f(x)$, and the fitted polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Part 6: Automatic cross-validation  with validation curves\n",
    "\n",
    "\n",
    "You recall from the lecture that the steps in Parts (3) and (4) can be implemented in an easier way using\n",
    "[`validation_curve()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html).\n",
    "Re-implement the cross-validation using this function by completing the code template below. \n",
    "\n",
    "*Hint:* Don't forget that you have to use\n",
    "the *negative* MSE as the relevant criterion, i.e., specify the argument\n",
    "`scoring='neg_mean_squared_error'` when calling `validation_curve()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# TODO: Create estimation pipeline\n",
    "\n",
    "# TODO: Complete the call to validation_curve()\n",
    "# train_scores, test_scores = validation_curve(\n",
    "#     estimator=...,\n",
    "#     X=X, y=y,\n",
    "#     param_name=...,\n",
    "#     param_range=...,\n",
    "#     scoring=..., \n",
    "#     cv=10\n",
    "# )\n",
    "\n",
    "# TODO: Average train_scores and test_scores across CV splits\n",
    "\n",
    "# TODO: Report the polynomial degree that minimizes the MSE on the test sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Exercise 2: Categorical features\n",
    "\n",
    "In this exercise, we practice fitting models which include categorical features in the regressor matrix $\\mathbf{X}$ using the Ames housing data set. There are several categorical variables in this data which come in two different kinds:\n",
    "\n",
    "1.  [Nominal categorical variables](https://en.wikipedia.org/wiki/Nominal_category) capture qualitative categories. For numerical purposes, we often encode these as integer values, but any particular\n",
    "    integer representation is arbitrary. It is a serious mistake to include such integer-valued categorical variables as *continuous* features in a model.\n",
    "\n",
    "    In the Ames housing data, the `Neighborhood` column is one such nominal categorical variable (which is stored as a string containing the neighborhood name).\n",
    "\n",
    "2.  [Ordinal categorical variables](https://en.wikipedia.org/wiki/Ordinal_data) represent data which have a natural ordering, but the distance between any two values can be arbitrary.\n",
    "    \n",
    "    For example, in the Ames housing data the `OverallQuality` variable is an ordinal categorical variable on a scale of 1–10. While a value of 2 is clearly better than a value of 1, it is up to\n",
    "    interpretation how much better.\n",
    "\n",
    "    Such variables can be included as categorical *dummy variables* in a model, not imposing any particular interpretation on the distance between two values. Alternatively, such variables can \n",
    "    be included as *continuous* variables, which imposes how the distance is interpreted. For example, including an ordinal categorical variable as a linear term in a model imposes\n",
    "    that moving from 1 to 2 has the same effect on the outcome variable as moving from 2 to 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Part 1: Creating the estimation sample\n",
    "\n",
    "We load the Ames data the same way as we did in the lectures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use local data/ folder\n",
    "DATA_PATH = '../../data'\n",
    "\n",
    "filename = f'{DATA_PATH}/ames_houses.csv'\n",
    "df = pd.read_csv(filename, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, perform the following data preprocessing steps:\n",
    "\n",
    "1.   Drop all observations which have any missing values for `SalePrice`, `OverallQuality`, or `Neighborhood`.\n",
    "2.   Tabulate how many neighborhoods have less than 40 observations, and drop observations from these neighborhoods from the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Part 2: Exploratory data analysis\n",
    "\n",
    "Before fitting a model, you should perform some exploratory data analysis to familiarize yourself with the data:\n",
    "\n",
    "1.  Compute the correlations of `SalePrice` with all numerical variables in the data. Which one is the most correlated?\n",
    "2.  Create a histogram for the variable `OverallQuality`, showing the number of observations for each of the possible values 1–10.\n",
    "\n",
    "    *Hint:* Create a `Series` with the number of observations per quality level and plot it as a bar chart using \n",
    "        [Series.plot.bar()](https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.bar.html).\n",
    "\n",
    "3.  Create a box plot showing the `SalePrice` by `OverallQuality`. \n",
    "\n",
    "    *Hint:* You can use the pandas plotting function [DataFrame.plot.box()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.box.html)\n",
    "    for this.\n",
    "\n",
    "4.  Create a box plot showing the `SalePrice` by `Neighborhood`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Part 3: Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into a training and a test sample, assigning 40% of observations to the test sample, and report the number of observations in each set.\n",
    "\n",
    "Stratify your split by `Neighborhood` so that each neighborhood is approximately equally represented in the training and test samples \n",
    "(use the `stratify` argument of \n",
    "[`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) for this).\n",
    "Specify a random seed of 1234.\n",
    "\n",
    "Note that you can pass the whole `DataFrame` to `train_test_split()` instead of individual `X` and `y` values.\n",
    "The function will then return two DataFrames, one containing the training and one the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Part 4: Predict sale price by neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an estimator pipeline to fit the model\n",
    "$$\n",
    "SalePrice_{ij} = \\mu_j + \\epsilon_{ij}\n",
    "$$\n",
    "where $i$ indexes observations and $j$ indexes neighborhoods. That is, the sale price for a house $i$ in neighborhood $j$ is predicted to be average sale price $\\mu_j$ in that neighborhood.\n",
    "\n",
    "In order to estimate this model, you'll have to convert the categorical string variable `Neighborhood` to a set of 0/1 dummy variabes. This can be achieved\n",
    "using the \n",
    "[OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n",
    "as a step in a pipeline.\n",
    "\n",
    "Fit the model on the training data, and report the RMSE both on the training and the test sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Part 5: Predict sale price with overall quality polynomial\n",
    "\n",
    "You are now asked to fit the following model:\n",
    "$$\n",
    "SalePrice_i = \\beta_0 + \\beta_1 OverallQuality + \\beta_1 OverallQuality^2 + \\dots + \\beta_1 OverallQuality^K + \\epsilon_i\n",
    "$$\n",
    "where the sale price is assumed to be a function of a polynomial in overall quality where we vary the polynomial degree $K$. We are thus implicitly treating the ordinal categorical variable `OverallQuality` as a continuous variable, which may or may not be admissible depending on the data. We will compare the estimation results to treating `OverallQuality` as a proper categorical in the next part.\n",
    "\n",
    "Use the following template code to fit the above model for polynomial degrees $d = 1, 2, \\dots, 9$ and compute the cross-validated RMSE on the training and test samples.\n",
    "For this you should use the function \n",
    "[`cross_validate()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html). \n",
    "This function returns a dictionary with the keys `'train_score'` and `'test_score'` which contain the computed scores for each split.\n",
    "Note that you need to pass `return_train_score=True`, otherwise the function does not return the scores for the training data.\n",
    "\n",
    "Create a plot showing the validation curves for both the training and test samples, and report the polynomial degree which minimizes the RMSE on the test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "degrees = np.arange(1, 10)\n",
    "\n",
    "rmse_train_mean = []\n",
    "rmse_test_mean = []\n",
    "\n",
    "for d in degrees:\n",
    "    # TODO: Create polynomial features + estimation pipeline\n",
    "\n",
    "    # TODO: Compute RMSE using cross-validation\n",
    "    # scores = cross_validate(\n",
    "    #     estimator=..., \n",
    "    #     X=X_train, y=y_train, \n",
    "    #     scoring=..., \n",
    "    #     cv=5,\n",
    "    #     return_train_score=True,\n",
    "    #     n_jobs=-1\n",
    "    # )\n",
    "\n",
    "    # TODO: Compute average RMSE over all CV splits\n",
    "    # rmse_train_mean.append(np.mean(-scores['train_score']))\n",
    "    # rmse_test_mean.append(np.mean(-scores['test_score']))\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Part 6: Predict sale price with overall quality dummies\n",
    "\n",
    "You are now interested whether treating the overall quality as a proper categorical variable improves the model performance. To this end, estimate the model\n",
    "$$\n",
    "SalePrice_{ij} = \\mu_j + \\epsilon_{ij}\n",
    "$$\n",
    "where $i$ indexes observations and $j$ indexes the overall quality categories 1–10. That is, the sale price for a house $i$ with overall quality $j$ is predicted to be average sale price $\\mu_j$ of all houses with that overall quality.\n",
    "\n",
    "Create an estimation pipeline to fit the model and perform cross-validation exactly as you did for the polynomial case above.\n",
    "Note that cross-validation is not needed for this model at all since it has no hyperparameters, but it creates a fair comparison to the polynomial case since we are estimating & predicting on the same sample using the same splits.\n",
    "\n",
    "Recreate the validation curve from above and add two horizontal lines showing the average RMSE from the dummy model for the training and tests sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create pipeline with dummies variables + estimation\n",
    "\n",
    "# TODO: Run cross-validation\n",
    "# scores = cross_validate(\n",
    "#     estimator=..., \n",
    "#     X=X_train, y=y_train, \n",
    "#     scoring=..., \n",
    "#     cv=5,\n",
    "#     return_train_score=True,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# TODO: Compute average RMSE over all CV splits\n",
    "# rmse_train_dummies_mean = np.mean(-scores['train_score'])\n",
    "# rmse_test_dummies_mean = np.mean(-scores['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Part 7: Compare predictions on the test sample\n",
    "\n",
    "Finally, use the best polynomial model and the dummy model estimated on the whole training sample, and compute the RMSE on the test sample. Which model performs better?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FIE463",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
