{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Polynomial under- and overfitting\n",
    "\n",
    "Consider the following non-linear model,\n",
    "$$\n",
    "y_i = f(x_i) + \\epsilon_i\\,,\\qquad\n",
    "f(x) = \\cos\\left(\\frac{3}{2} \\pi x \\right)\n",
    "$$\n",
    "where $y_i$ is a trigonometric function of $x_i$ but is measured with an additive error $\\epsilon_i$. In this exercise, we are going to approximate $y_i$ using polynomials in $x_i$ of varying degrees:\n",
    "\n",
    "1. Create a sample of size $N=50$ where the $x_i$ are randomly drawn from a uniform distribution on the interval $[0, 1]$ and \n",
    "    $\\epsilon_i \\stackrel{\\text{iid}}{\\sim} N(0, 0.2^2)$. Initialize your RNG with a seed of 1234.\n",
    "    Then generate $y_i$ according to the equation given above. \n",
    "    \n",
    "    Create a scatter plot of the sample $(x_i, y_i)$ and add a line depicting the true non-linear relationship (without measurement error).\n",
    "\n",
    "    *Hint:* The cosine function and the constant $\\pi$ are implemented as `np.cos()` and `np.pi` in NumPy.\n",
    "\n",
    "2. Use the \n",
    "    [`PolynomialFeatures`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)\n",
    "    transformation and \n",
    "    [`LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "    to approximate $y$ as a polynomial in $x$. Fit this model using the polynomial degrees\n",
    "    $d \\in \\{0, 1, 2, 3, 10, 15\\}$. You should build a pipeline (e.g., using \n",
    "    [`make_pipeline()`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html))\n",
    "    to create the polynomial and perform the fitting in one step.\n",
    "    \n",
    "    Create a figure with 6 panels, one for each polynomial degree. \n",
    "    Each panel should show the sample scatter plot, the true function $y = f(x)$ and the polynomial approximation of a given \n",
    "    degree.\n",
    "\n",
    "    How does the quality of the approximation change as you increase $d$? Do higher-order polynomials always perform better?\n",
    "\n",
    "    *Hint:* When creating polynomials with `PolynomialFeatures(..., include_bias=True)`, you need to fit the model *without*\n",
    "    an additional intercept as the intercept is already included in the polynomial.\n",
    "\n",
    "\n",
    "3.  You want to find the optimal polynomial degree using cross-validation. For this purpose,\n",
    "    program a function with the signature \n",
    "\n",
    "    ```python\n",
    "    def compute_average_mse(d, x, y, n_splits):\n",
    "        \"\"\"\n",
    "        Compute mean squared error averaged across splits in k-fold cross-validation.\n",
    "        \"\"\"\n",
    "    ```\n",
    "    which takes as arguments the polynomial degree $d$, the \n",
    "    sample observations $(x, y)$ and the number of splits `n_splits`, and returns the mean squared error (MSE) for the\n",
    "    test sample averaged across all splits. \n",
    "\n",
    "    Using the function you wrote, compute the average MSEs for polynomial degrees $d = 0,\\dots,15$ using 10 splits.\n",
    "    Use these to create a plot of the average MSE on the $y$-axis against $d$ on the $x$-axis.\n",
    "    Which degree $d$ results in the lowest average MSE? \n",
    "\n",
    "    *Hint:* You do not need to assign training/test samples manually. Use the \n",
    "    [`KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) class and call\n",
    "    its `split()` method to do the work for you!\n",
    "\n",
    "    *Hint:* To compute the MSE for each test sample, you can use \n",
    "    [`mean_squared_error()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html).\n",
    "\n",
    "4.  Re-estimate the model using the optimal polynomial degree you just found and create a scatter plot with the original data,\n",
    "    the true function $y = f(x)$ and the fitted polynomial.\n",
    "\n",
    "5.  You recall from the lecture that the steps in Part (3) can be implemented in an easier way using\n",
    "    [`cross_val_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html).\n",
    "    Re-implement the cross-validation using this function. \n",
    "    \n",
    "    *Hint:* Don't forget that you have to use\n",
    "    the *negative* MSE as the relevant criterion, i.e., specify the argument\n",
    "    `scoring='neg_mean_squared_error'` when calling `cross_val_score()`.\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FIE463",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
